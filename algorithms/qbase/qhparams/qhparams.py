# 
# Author(s):
# Matteo Spallanzani <spmatteo@iis.ee.ethz.ch>
# 
# Copyright (c) 2020-2022 ETH Zurich and University of Bologna.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# 

"""Handle the interchangeability of offsets, quanta, and clipping bounds.

Given a quantiser, its offset :math:`z`, quantum :math:`\varepsilon` and
number of levels :math:`N` are related to the clipping bounds :math:`alpha`
and :math:`beta` by the following relationships:

.. math::
   \alpha &= z \varepsilon \,, \\
   \beta  &= (z + N - 1) \varepsilon \,.

Therefore, we can always reconstruct the clipping bounds of a quantiser if we
know its offset and quantum.

Quantisers are usually applied either to weights or to features; thus, we also
distinguish between *weight quantisers* and *feature quantisers*. Weight
quantisers take in input *shadow parameters* (real numbers represented by
floating-point values), which are evolved by the training algorithm as
iterations progress. The distribution of shadow parameters is the first knob
to tune to train quantised neural networks. Differently, feature quantisers
process inputs generated by upstream modules, whose distribution the training
algorithm has usually no control over.

An opportunity to learn better quantised models it to learn the quantisers
themselves; thus, we distinguish between *static quantisers* and *dynamic
quantisers*. Static quantisers are such that their offset and quantum, once
initialised, do not change. Dynamic quantisers, on the other hand, can evolve
their quantum, their offset, or both.

This module implements the functions to initialise and change quantisers.

"""

import torch
import inspect  # use introspection to print function names into error messages
from typing import Tuple

from ..qrange import IMPLICIT_STEP
from ..qrange import UNKNOWN, QRange
from quantlib.utils.messages import quantlib_wng_header, quantlib_err_header


# aliases (for readability)
UNSPECIFIED = torch.Tensor([float('nan')])


def create_qhparams(qrange: QRange) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
    """Initialise the hyper-parameters describing a quantiser.

    Note that all the output ``torch.Tensor``s will have ``ndim == 1`` and
    ``shape == (1,)``.
    """

    zero     = torch.Tensor([qrange.offset]) if qrange.offset is not UNKNOWN else UNSPECIFIED
    n_levels = torch.Tensor([qrange.n_levels])
    step     = torch.Tensor([qrange.step])
    scale    = UNSPECIFIED

    return zero, n_levels, step, scale


def _check_a_b(a: torch.Tensor, b: torch.Tensor):
    if not torch.all(a < b):
        caller_name = inspect.getouterframes(inspect.currentframe())[1].function    # https://stackoverflow.com/a/2529895 and https://docs.python.org/3/library/inspect.html#inspect.getouterframes
        raise ValueError(quantlib_err_header(obj_name=caller_name) + f"requires that all the components of {a} are strictly lower than the corresponding components of {b}.")


def get_zero_scale(a: torch.Tensor,
                   b: torch.Tensor,
                   n_levels: torch.Tensor,
                   step: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    """Compute the offset and quantum to cover an interval with given bounds.

    To ensure fake-to-true convertibility, it is crucial that fake-quantised
    ranges are compatible with all the values that are used at training time,
    during the fake-quantised stage. For instance, it is usually the case in
    convolutional neural networks that feature maps are zero-padded even
    during the fake-quantised stage. Therefore, we want zero to be in the
    fake-quantisation range. A simple way to ensure this property is enforcing
    fake-quantisation ranges to be scalar multiples of integer ranges.

    When initialising a fake-quantisation range from a given real range (in
    practice, a range of floating-point numbers), a naive strategy would
    suggest that we compute the quantum :math:`\varepsilon` as

    .. math::
       \varepsilon = (b - a) / (N - 1) \,.

    However, doing so does not guarantee that :math:`a = z \varepsilon` for
    some integer :math:`z`.

    This function is not supposed to be used in conjunction with special
    quantisation ranges (binary, ternary), but more standard unsigned and
    signed integers (two's complement) or "limp" signed integers
    (sign/magnitude notation).

    """
    _check_a_b(a, b)

    if not torch.all(step == IMPLICIT_STEP):  # this function is not thought to operate with the sign range
        raise NotImplementedError

    scale = (b - a) / (n_levels / torch.pow(n_levels - 1, 2))
    zero = torch.floor(a / scale)
    return zero, scale


def get_scale(a: torch.Tensor,
              b: torch.Tensor,
              zero: torch.Tensor,
              n_levels: torch.Tensor,
              step: torch.Tensor) -> torch.Tensor:
    """Compute the quantum of a quantisation range with fixed offset."""
    _check_a_b(a, b)

    # TODO: find a more elegant way to ensure that the parameters are on the same device (attribute this responsibility to the right objects)
    a = a.to(device=zero.device)
    b = b.to(device=zero.device)

    where_a_negative = a < 0.0
    where_a_zero     = a == 0.0
    where_a_positive = a > 0.0
    where_b_negative = b < 0.0
    where_b_zero     = b == 0.0
    where_b_positive = b > 0.0

    case_ab_1 = where_a_negative & where_b_negative
    case_ab_2 = where_a_negative & where_b_zero
    case_ab_3 = where_a_negative & where_b_positive
    case_ab_4 = where_a_zero     & where_b_positive
    case_ab_5 = where_a_positive & where_b_positive

    min_ = zero
    max_ = zero + (n_levels - 1) * step
    where_min_negative = min_ < 0.0
    where_min_zero     = min_ == 0.0
    where_min_positive = min_ > 0.0
    where_max_negative = max_ < 0.0
    where_max_zero     = max_ == 0.0
    where_max_positive = max_ > 0.0

    case_mm_1 = where_min_negative & where_max_negative
    case_mm_2 = where_min_negative & where_max_zero
    case_mm_3 = where_min_negative & where_max_positive  # this is the case of sign ranges
    case_mm_4 = where_min_zero     & where_max_positive
    case_mm_5 = where_min_positive & where_max_positive

    case_1_1 = case_ab_1 & case_mm_1
    case_1_2 = case_ab_1 & case_mm_2
    case_1_3 = case_ab_1 & case_mm_3
    case_1_4 = case_ab_1 & case_mm_4
    case_1_5 = case_ab_1 & case_mm_5

    case_2_1 = case_ab_2 & case_mm_1
    case_2_2 = case_ab_2 & case_mm_2
    case_2_3 = case_ab_2 & case_mm_3
    case_2_4 = case_ab_2 & case_mm_4
    case_2_5 = case_ab_2 & case_mm_5

    case_3_1 = case_ab_3 & case_mm_1
    case_3_2 = case_ab_3 & case_mm_2
    case_3_3 = case_ab_3 & case_mm_3
    case_3_4 = case_ab_3 & case_mm_4
    case_3_5 = case_ab_3 & case_mm_5

    case_4_1 = case_ab_4 & case_mm_1
    case_4_2 = case_ab_4 & case_mm_2
    case_4_3 = case_ab_4 & case_mm_3
    case_4_4 = case_ab_4 & case_mm_4
    case_4_5 = case_ab_4 & case_mm_5

    case_5_1 = case_ab_5 & case_mm_1
    case_5_2 = case_ab_5 & case_mm_2
    case_5_3 = case_ab_5 & case_mm_3
    case_5_4 = case_ab_5 & case_mm_4
    case_5_5 = case_ab_5 & case_mm_5

    case_i   = case_1_1 | case_1_2 | case_1_3 | case_2_1 | case_2_2 | case_2_3 | case_3_1 | case_3_2
    case_ii  = case_3_3
    case_iii = case_3_4 | case_3_5 | case_4_3 | case_4_4 | case_4_5 | case_5_3 | case_5_4 | case_5_5
    case_iv  = case_1_4 | case_1_5 | case_2_4 | case_2_5 | case_4_1 | case_4_2 | case_5_1 | case_5_2

    eps = torch.zeros_like(zero)
    eps[case_i]   = a[case_i] / min_[case_i]
    eps[case_ii]  = torch.max(a[case_ii] / min_[case_ii], b[case_ii] / max_[case_ii])
    eps[case_iii] = b[case_iii] / max_[case_iii]
    if torch.any(case_iv):
        print(quantlib_wng_header(obj_name=inspect.currentframe().f_code.co_name) + "can not cover some range [a, b] with a scalar multiple of the provided integer range.")
        eps[case_iv] = torch.max(a[case_iv].abs(), b[case_iv].abs()) / torch.max(min_[case_iv].abs(), max_[case_iv].abs())

    assert torch.all(eps > 0.0)

    return eps


def get_clipping_bounds(zero: torch.Tensor, n_levels: torch.Tensor, step: torch.Tensor, scale: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    """Compute the clipping bounds of a given fake-quantised range."""
    clip_lo = zero * scale
    clip_hi = (zero + (n_levels - 1) * step) * scale
    return clip_lo, clip_hi
